{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#importing libraries\r\n",
    "import tensorflow as tf\r\n",
    "from keras_preprocessing.image import ImageDataGenerator\r\n",
    "import os\r\n",
    "import keras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# There are two classes of interests among the images in dataset\r\n",
    "cls_of_int = ['Covid', 'Normal']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#setting the path variables for train, test and validation data\r\n",
    "basePath = \"Data\"\r\n",
    "trainPath = os.path.join(basePath,\"train\")\r\n",
    "testPath = os.path.join(basePath,\"test\")\r\n",
    "validPath = os.path.join(basePath,\"valid\")\r\n",
    "\r\n",
    "trainCovid = os.path.join(trainPath,\"Covid\")\r\n",
    "trainNormal = os.path.join(trainPath,\"Normal\")\r\n",
    "\r\n",
    "testCovid = os.path.join(testPath,\"Covid\")\r\n",
    "testNormal = os.path.join(testPath,\"Normal\")\r\n",
    "\r\n",
    "validCovid = os.path.join(basePath,\"valid\",\"Covid\")\r\n",
    "validNormal = os.path.join(basePath,\"valid\",\"Normal\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# using a data generator for data augmentation, the volume of training data is increased using data augmentation techniques\r\n",
    "train_data_generator = ImageDataGenerator(\r\n",
    "    rotation_range=30,\r\n",
    "    width_shift_range=0.2,\r\n",
    "    height_shift_range=0.2,\r\n",
    "    rescale=1.0/255, # Normalizing the image\r\n",
    "    shear_range=0.2,\r\n",
    "    zoom_range=0.2,\r\n",
    "    vertical_flip = False,\r\n",
    "    fill_mode='nearest',\r\n",
    "    featurewise_center = True,\r\n",
    "    featurewise_std_normalization = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# The data generator for validation data, normalizing of the image is done\r\n",
    "valid_data_generator = ImageDataGenerator(rescale = 1./255)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# The data generator for test data, normalizing of the image is done\r\n",
    "test_data_generator = ImageDataGenerator(rescale = 1./255)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Read data from directory for training data\r\n",
    "train_generator = train_data_generator.flow_from_directory(\r\n",
    "    directory=trainPath,\r\n",
    "    target_size=(224, 224),# resizing the image\r\n",
    "    color_mode=\"rgb\",\r\n",
    "    batch_size=32,\r\n",
    "    class_mode=\"binary\", # class mode is binary as there are only 2 classes\r\n",
    "    shuffle=True,\r\n",
    "    seed=42\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 11047 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Read data from directory for validation data\r\n",
    "valid_generator = valid_data_generator.flow_from_directory(\r\n",
    "    directory= validPath,\r\n",
    "    target_size=(224, 224),# resizing the image\r\n",
    "    color_mode=\"rgb\",\r\n",
    "    batch_size=32,\r\n",
    "    class_mode=\"binary\", # class mode is binary as there are only 2 classes\r\n",
    "    shuffle=True,\r\n",
    "    seed=42\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2208 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Read data from directory for testing data\r\n",
    "test_generator = test_data_generator.flow_from_directory(\r\n",
    "    directory= testPath,\r\n",
    "    target_size=(224, 224),# resizing the image\r\n",
    "    color_mode=\"rgb\",\r\n",
    "    batch_size=11,\r\n",
    "    class_mode=\"binary\", # class mode is binary as there are only 2 classes\r\n",
    "    shuffle=False,\r\n",
    "    seed=42\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2761 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Downloading the Xception model.\r\n",
    "pretrained_model = tf.keras.applications.Xception(\r\n",
    "        weights='imagenet',\r\n",
    "        include_top=False ,\r\n",
    "        input_shape=(224,224,3)\r\n",
    "    )\r\n",
    "pretrained_model.trainable = False\r\n",
    "\r\n",
    "# Added Pooling layer and a sigmoid activation layer.    \r\n",
    "model = tf.keras.Sequential([ \r\n",
    "        pretrained_model,   \r\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\r\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Compiling the model with Adam optimizer and binary cross entropy loss function\r\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
    "model.compile(optimizer = opt ,\r\n",
    "              loss=\"binary_crossentropy\",\r\n",
    "              metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# To display the summary of the model\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 7, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 20,865,578\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# specifying the batch sizes\r\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\r\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\r\n",
    "STEP_SIZE_TEST = test_generator.n//train_generator.batch_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Fitting the model with 20 epochs\r\n",
    "model.fit_generator(generator=train_generator,\r\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\r\n",
    "                    validation_data=valid_generator,\r\n",
    "                    validation_steps=STEP_SIZE_VALID,\r\n",
    "                    epochs=20\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "345/345 [==============================] - 1321s 4s/step - loss: 0.4331 - accuracy: 0.8064 - val_loss: 0.3404 - val_accuracy: 0.8573\n",
      "Epoch 2/20\n",
      "345/345 [==============================] - 1226s 4s/step - loss: 0.3150 - accuracy: 0.8706 - val_loss: 0.3557 - val_accuracy: 0.8501\n",
      "Epoch 3/20\n",
      "345/345 [==============================] - 1276s 4s/step - loss: 0.2995 - accuracy: 0.8782 - val_loss: 0.3039 - val_accuracy: 0.8741\n",
      "Epoch 4/20\n",
      "345/345 [==============================] - 1156s 3s/step - loss: 0.2920 - accuracy: 0.8850 - val_loss: 0.3091 - val_accuracy: 0.8736\n",
      "Epoch 5/20\n",
      "345/345 [==============================] - 1131s 3s/step - loss: 0.2799 - accuracy: 0.8875 - val_loss: 0.2742 - val_accuracy: 0.8909\n",
      "Epoch 6/20\n",
      "345/345 [==============================] - 1106s 3s/step - loss: 0.2733 - accuracy: 0.8961 - val_loss: 0.3189 - val_accuracy: 0.8673\n",
      "Epoch 7/20\n",
      "345/345 [==============================] - 2098s 6s/step - loss: 0.2611 - accuracy: 0.8947 - val_loss: 0.3001 - val_accuracy: 0.8809\n",
      "Epoch 8/20\n",
      "345/345 [==============================] - 5977s 17s/step - loss: 0.2593 - accuracy: 0.8932 - val_loss: 0.2638 - val_accuracy: 0.8949\n",
      "Epoch 9/20\n",
      "345/345 [==============================] - 1499s 4s/step - loss: 0.2630 - accuracy: 0.8977 - val_loss: 0.2822 - val_accuracy: 0.8913\n",
      "Epoch 10/20\n",
      "345/345 [==============================] - 1541s 4s/step - loss: 0.2578 - accuracy: 0.8999 - val_loss: 0.2820 - val_accuracy: 0.8886\n",
      "Epoch 11/20\n",
      "345/345 [==============================] - 1143s 3s/step - loss: 0.2650 - accuracy: 0.8933 - val_loss: 0.2595 - val_accuracy: 0.8990\n",
      "Epoch 12/20\n",
      "345/345 [==============================] - 1134s 3s/step - loss: 0.2428 - accuracy: 0.9069 - val_loss: 0.2802 - val_accuracy: 0.8881\n",
      "Epoch 13/20\n",
      "345/345 [==============================] - 1294s 4s/step - loss: 0.2450 - accuracy: 0.9043 - val_loss: 0.2781 - val_accuracy: 0.8872\n",
      "Epoch 14/20\n",
      "345/345 [==============================] - 1298s 4s/step - loss: 0.2487 - accuracy: 0.9023 - val_loss: 0.2845 - val_accuracy: 0.8836\n",
      "Epoch 15/20\n",
      "345/345 [==============================] - 1144s 3s/step - loss: 0.2513 - accuracy: 0.8950 - val_loss: 0.2423 - val_accuracy: 0.9103\n",
      "Epoch 16/20\n",
      "345/345 [==============================] - 1092s 3s/step - loss: 0.2353 - accuracy: 0.9069 - val_loss: 0.2328 - val_accuracy: 0.9117\n",
      "Epoch 17/20\n",
      "345/345 [==============================] - 1125s 3s/step - loss: 0.2502 - accuracy: 0.8989 - val_loss: 0.2374 - val_accuracy: 0.9085\n",
      "Epoch 18/20\n",
      "345/345 [==============================] - 1106s 3s/step - loss: 0.2433 - accuracy: 0.9042 - val_loss: 0.2410 - val_accuracy: 0.9081\n",
      "Epoch 19/20\n",
      "345/345 [==============================] - 1052s 3s/step - loss: 0.2402 - accuracy: 0.9046 - val_loss: 0.2800 - val_accuracy: 0.8832\n",
      "Epoch 20/20\n",
      "345/345 [==============================] - 1048s 3s/step - loss: 0.2390 - accuracy: 0.9086 - val_loss: 0.2506 - val_accuracy: 0.8990\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28eb259f880>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model.evaluate(valid_generator,steps=STEP_SIZE_VALID)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "69/69 [==============================] - 187s 3s/step - loss: 0.2506 - accuracy: 0.8990\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.25055280327796936, 0.8990036249160767]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(test_generator)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "251/251 [==============================] - 8s 28ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "score = model.evaluate(valid_generator,batch_size=32)\r\n",
    "print(\"Accuracy: {:.2f}%\".format(score[1] * 100)) \r\n",
    "print(\"Loss: \",score[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "69/69 [==============================] - 12s 179ms/step - loss: 0.2574 - accuracy: 0.8958\n",
      "Accuracy: 89.58%\n",
      "Loss:  0.25741082429885864\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "score = model.evaluate(test_generator,batch_size=11)\r\n",
    "print(\"Accuracy: {:.2f}%\".format(score[1] * 100)) \r\n",
    "print(\"Loss: \",score[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "251/251 [==============================] - 7s 27ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Accuracy: 0.00%\n",
      "Loss:  0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save('imagegeneratormodelxc')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: imagegeneratormodelxc\\assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\Ajay\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loaded_model = keras.models.load_model('imagegeneratormodelxc')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val_score = loaded_model.evaluate(valid_generator)\r\n",
    "print(\"Accuracy: {:.2f}%\".format(val_score[1] * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "69/69 [==============================] - 17s 196ms/step - loss: 0.2574 - accuracy: 0.8958\n",
      "Accuracy: 89.58%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_score = loaded_model.evaluate(test_generator)\r\n",
    "print(\"Accuracy: {:.2f}%\".format(test_score[1] * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "251/251 [==============================] - 20s 79ms/step - loss: 0.2775 - accuracy: 0.8877\n",
      "Accuracy: 88.77%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "b7ddd633ae6f8035a3efd49b5d587b4e36579d898fb8d708eb7adffb43601494"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}